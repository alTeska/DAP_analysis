{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Analysis - Use Old Summary Statistics and Similarity Measure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import argrelmin, argrelmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dap import DAPcython\n",
    "from dap.utils import obs_params, load_current\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 1e-2\n",
    "params, labels = obs_params(reduced_model=False)\n",
    "data_dir = '/home/alteska/Desktop/LFI_DAP/data/rawData/2015_08_26b.dat'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './parameters/'\n",
    "dir = glob.glob(directory + '*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_start = dir[0].find('dap_')\n",
    "fname_stop = dir[0].find('n_')\n",
    "fname = dir[0][fname_start:fname_stop] + '.csv'\n",
    "\n",
    "df_param = pd.read_csv(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate DAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the input data\n",
    "Ir, vr, tr, t_onr, t_offr, dtr = load_current(data_dir, protocol='rampIV', ramp_amp=3.1)\n",
    "Is, vs, ts, t_ons, t_offs, dts = load_current(data_dir, protocol='IV', ramp_amp=1)\n",
    "\n",
    "# define a model\n",
    "dap = DAPcython(-75, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run models on original parameters\n",
    "U_step = dap.simulate(dts, ts, Is)\n",
    "U_ramp = dap.simulate(dtr, tr, Ir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate the similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_step = distance.euclidean(vs, U_step)\n",
    "d_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_ramp = distance.euclidean(vr, U_ramp)\n",
    "d_ramp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_step+d_ramp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run for all cells and save into the the DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paramT = df_param.transpose()\n",
    "df_paramT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paramT.drop('Unnamed: 0', inplace=True)\n",
    "df_paramT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daps = []\n",
    "U_steps = []\n",
    "U_ramps = []\n",
    "\n",
    "for i, j in tqdm(df_paramT.iterrows()):\n",
    "    # get parameters\n",
    "    par_temp = j.values\n",
    "\n",
    "    # define a model\n",
    "    daps.append(DAPcython(-75, j))\n",
    "\n",
    "    # run model\n",
    "    U_steps.append(dap.simulate(dts, ts, Is))\n",
    "    U_ramps.append(dap.simulate(dtr, tr, Ir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the features for each parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ramp_sum_stats(v, t, dt, t_on, t_off):\n",
    "    \"\"\"Calculate summary statistics of a single run\"\"\"\n",
    "    stats = []\n",
    "    stats_idx = []\n",
    "#     v = v.transpose()\n",
    "    N = v.shape[0]\n",
    "\n",
    "    # resting potential\n",
    "    rest_pot = np.mean(v[t<t_on])\n",
    "    rest_pot_std = np.std(v[int(.9*t_on/dt):int(t_on/dt)])   # TODO: add if needed\n",
    "\n",
    "    # RMSE\n",
    "#     n = len(self.v0)\n",
    "#     rmse = np.linalg.norm(v - self.v0) / np.sqrt(n)\n",
    "\n",
    "    # more then one AP:\n",
    "    multiple_AP = np.shape(np.where(v > 0))[1]\n",
    "\n",
    "    #case without any action potential or more then one AP\n",
    "    if (np.all(v <= 20)):\n",
    "        AP_onsets = 999\n",
    "        AP_amp = 999\n",
    "        AP_width = 999\n",
    "        DAP_amp = 999\n",
    "        DAP_width = 999\n",
    "        DAP_deflection = 999\n",
    "        DAP_time = 999\n",
    "        mAHP = 999\n",
    "        fAHP = 999\n",
    "\n",
    "    else:\n",
    "        threshold = -30\n",
    "        # hyperpolarization after DAP\n",
    "        mAHP_idx = np.argmin(v)\n",
    "        mAHP = v[mAHP_idx]\n",
    "\n",
    "        # Action potential\n",
    "        AP_onsets = np.where(v > threshold)[0]\n",
    "        AP_start = AP_onsets[0]\n",
    "        AP_end = AP_onsets[-1]\n",
    "        AP_max_idx = AP_start + np.argmax(v[AP_start:AP_end])\n",
    "        AP_max = v[AP_max_idx]\n",
    "        AP_amp = AP_max - rest_pot\n",
    "\n",
    "        # AP width\n",
    "        AP_onsets_half_max = np.where(v > (AP_max+rest_pot)/2)[0]\n",
    "        AP_width = t[AP_onsets_half_max[-1]] - t[AP_onsets_half_max[0]]\n",
    "\n",
    "        # DAP: fAHP\n",
    "        v_dap = v[AP_max_idx:]\n",
    "\n",
    "        fAHP_idx = argrelmin(v[AP_max_idx:])[0][0] + AP_max_idx\n",
    "        fAHP = v[fAHP_idx]\n",
    "\n",
    "        # DAP amplitude\n",
    "        DAP_max_idx = argrelmax(v_dap)[0][1] + AP_max_idx\n",
    "        DAP_max = v[DAP_max_idx]\n",
    "        DAP_amp = DAP_max - rest_pot\n",
    "\n",
    "        DAP_deflection = DAP_amp - (fAHP - rest_pot)\n",
    "        DAP_time = t[DAP_max_idx] - t[AP_max_idx]    # Time between AP and DAP maximum\n",
    "\n",
    "        # Width of DAP: between fAHP and halfsize of fAHP after DAP max\n",
    "        vnorm = v[DAP_max_idx:] - rest_pot\n",
    "\n",
    "        if np.any((abs(vnorm) < abs(fAHP - rest_pot)/2)):\n",
    "            half_max = np.where((abs(vnorm) < abs(fAHP - rest_pot)/2))[0]\n",
    "\n",
    "            DAP_width_idx = DAP_max_idx + half_max[0]\n",
    "            DAP_width = (DAP_width_idx - fAHP_idx) * dt\n",
    "        else:\n",
    "            DAP_width = 999\n",
    "\n",
    "\n",
    "    sum_stats_vec = np.array([\n",
    "                    rest_pot,\n",
    "                    AP_amp,\n",
    "                    AP_width,\n",
    "                    fAHP,\n",
    "                    DAP_amp,\n",
    "                    DAP_width,\n",
    "                    DAP_deflection,\n",
    "                    DAP_time,\n",
    "                    mAHP,\n",
    "                    ])\n",
    "\n",
    "\n",
    "    return sum_stats_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = calc_ramp_sum_stats(U_ramps[0], tr, dtr, t_onr, t_offr)\n",
    "pd.DataFrame(data=sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Step Current: Outside of The Function\n",
    "to pick required parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v, t, dt, t_on, t_off = U_steps[0], ts, dts, t_ons, t_offs\n",
    "\n",
    "\"\"\"Calculate summary statistics\"\"\"\n",
    "stats = []\n",
    "N = v.shape[0]\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(v);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put everything to -10 that is below -10 or has negative slope\n",
    "ind = np.where(v < -10)\n",
    "v[ind] = -10\n",
    "ind = np.where(np.diff(v) < 0)\n",
    "v[ind] = -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(v);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.diff(v.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = v.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.diff(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remaining negative slopes are at spike peaks\n",
    "ind = np.where(np.diff(v) > 0)\n",
    "ind = ind[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose one spike time within close spike times (window of 0.5 ms)\n",
    "ind1 = np.array(ind)\n",
    "ind1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_times = np.array(t)[ind]\n",
    "spike_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_times_stim = spike_times[(spike_times > t_on) & (spike_times < t_off)]\n",
    "spike_times_stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_stim1 = ind1[(spike_times > t_on) & (spike_times < t_off)]\n",
    "ind_stim1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ind_stim1 = ind_stim1[np.append(1,np.diff(spike_times_stim))>0.5] # ??????????????????????\n",
    "ind_stim = ind_stim1.astype(int)\n",
    "ind_stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHY THIS?\n",
    "# spike_times_stim = spike_times_stim[np.append(1,np.diff(spike_times_stim))>0.5]\n",
    "# spike_times_stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firing rate\n",
    "firing_rate = 1e3*np.absolute(spike_times_stim.shape[0]/(t_off-t_on))\n",
    "\n",
    "time_1st_spike = spike_times_stim[spike_times_stim>t_on][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average spike width\n",
    "if spike_times_stim.shape[0] == 1:\n",
    "    delta_ind_spik = np.round(t[(t>t_on) & (t<t_off)].shape[0]/2).astype(int)\n",
    "else:\n",
    "    ISI = np.diff(spike_times_stim).astype(float)\n",
    "    delta_ind_spik = np.round(np.min(ISI)/(2*dt)).astype(int)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ISI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_ind_spik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = v.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_width1 = np.zeros_like(spike_times_stim)\n",
    "for i_sp in range(spike_times_stim.shape[0]):\n",
    "    # voltages post-spike\n",
    "    x_isi = v[ind_stim[i_sp].astype(int):np.minimum(ind_stim[i_sp].astype(int)+delta_ind_spik,N)]\n",
    "    t_isi = t[ind_stim[i_sp].astype(int):np.minimum(ind_stim[i_sp].astype(int)+delta_ind_spik,N)]\n",
    "    \n",
    "    x_post = x_isi[0:np.maximum(np.argmin(x_isi),2)]\n",
    "    t_post = t_isi[0:np.maximum(np.argmin(x_isi),2)]\n",
    "\n",
    "   \n",
    "    # half-maximum voltage\n",
    "    x_half_max = 0.5*(x_post[-1]+x_post[0])\n",
    "\n",
    "    # voltages pre-spike\n",
    "    x_pre = v[np.maximum(ind_stim[i_sp].astype(int)-delta_ind_spik,0):ind_stim[i_sp].astype(int)]\n",
    "    t_pre = t[np.maximum(ind_stim[i_sp].astype(int)-delta_ind_spik,0):ind_stim[i_sp].astype(int)]\n",
    "\n",
    "    spike_width1[i_sp] = t_post[np.argmin(np.absolute(x_post - x_half_max))]-t_pre[np.argmin(np.absolute(x_pre - x_half_max))]\n",
    "\n",
    "spike_width = np.mean(spike_width1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_begin = t[(t>t_on) & (t<time_1st_spike)]\n",
    "v_begin = v[(t>t_on) & (t<time_1st_spike)]\n",
    "t_begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.diff(v_begin.transpose(), n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latency from stimulus onset to first spike and mean action potential overshoot\n",
    "if t_begin.shape[0] == 0:\n",
    "    AP_latency = 10000\n",
    "    AP_overshoot_mn = np.max(v[(t > t_on) & (t < t_off)])\n",
    "elif t_begin.shape[0] == 1 or t_begin.shape[0] == 2:\n",
    "    AP_latency = np.absolute(t_begin[0])\n",
    "    AP_overshoot_mn = np.absolute(np.mean(v[ind_stim]))\n",
    "else:\n",
    "    AP_latency = np.absolute(t_begin[np.argmax(np.diff(v_begin.transpose(), n=2))])\n",
    "    AP_overshoot_mn = np.absolute(np.mean(v[ind_stim]))\n",
    "\n",
    "# resting potential mean and std\n",
    "rest_pot = np.mean(v[t<t_on])\n",
    "rest_pot_std = np.std(v[int(.9*t_on/dt):int(t_on/dt)])\n",
    "\n",
    "# ISI mean and std\n",
    "if spike_times_stim.shape[0] > 1:\n",
    "    ISImom = np.array([np.mean(ISI),np.std(ISI)])\n",
    "else:\n",
    "    ISImom = np.array([1000.]*2)\n",
    "ISI1 = np.array([1000.]*2)\n",
    "ISI1[0:np.maximum(0,spike_times_stim.shape[0]-1)] = ISImom[0:np.maximum(0,spike_times_stim.shape[0]-1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dap_kernel",
   "language": "python",
   "name": "dap_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
